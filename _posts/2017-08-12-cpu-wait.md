---
layout: post
title: "CPU wait"
date: 2017-08-12
---

![slow](/images/monkey.jpeg)


Let's set the scene.  We are investigating a host that has a job/application taking a very long time to complete.  This process writes database backup files to local disk.  This host lives in AWS and is of `m3.medium` instance type.  

We will use a tool called `vmstat`.  According to the man pages, `vmstat` reports virtual memory statistics.  It has many flags to drive it and I encourage you to explore it.

`vmstat` not only cares about memory stats, but it is also a great tool to get information about block IO and CPU.

With this knowledge in hand, let's if `vmstat` can tell us anything about our system during the backup job.  

In the terminal, I type the following.  The `1` tells `vmstat` to measure statistics every second. The `5` instructs `vmstat` to report stats only five times.

* NOTE: the first line is the averages since last boot and should not be used in this.

```bash
[bradley@entanglement~]$ vmstat 1 5
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 2  1 403256 602848  17836 400356    5   15    50    50  207  861 13  3 83  1  0
 1  0 403256 601568  18892 400496    0    0  1048   364  337 1903  5  7  0 88  0
 0  1 403256 600816  19640 400568    0    0   748     0  259 1142  6  4  0 90  0
 0  1 403256 600300  20116 400800    0    0   476     0  196  630  8  5  0 87  0
 0  1 403256 599328  20792 400792    0    0   676     0  278 1401  7  5  0 88  0
```


Now, by looking at the stats above we can see `wa` column under `cpu` heading has a high percentage.  This is the time the CPU is waiting on IO.  It would seem, we would need more investigation, that our backup writing to disk is a possible suspect of why our host and job are slow.  

* `vmstat` is powerful, but should not be the only tool you use to diagnose a troubled host.


We will dive into more commands in the future.



__P.S.__  The culprit turned out to be a slow disk.  We provisioned the AWS instance with default low impact disk.  Lesson learned!
